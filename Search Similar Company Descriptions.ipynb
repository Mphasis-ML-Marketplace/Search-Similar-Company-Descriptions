{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, tune, and deploy a custom ML model using Search Similar Company Descriptions Algorithm from AWS Marketplace \n",
    "\n",
    "\n",
    "Given a company name and the no. of companies to rank, this ML solution provides top companies with similar descriptions as output.\n",
    "\n",
    "This sample notebook shows you how to train a custom ML model using Search Similar Company Descriptions Algorithm from AWS Marketplace.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Vector Search for Company Description. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure the dataset](#B.-Configure-the-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train a machine learning model](#3:-Train-a-machine-learning-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-a-model)\n",
    "1. [Deploy model and verify results](#4:-Deploy-model-and-verify-results)\n",
    "    1. [Deploy trained model](#A.-Deploy-trained-model)\n",
    "    1. [Create input payload](#B.-Create-input-payload)\n",
    "    1. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    1. [Visualize output](#D.-Visualize-output)\n",
    "    1. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "1. [Perform Batch inference](#5.-Perform-Batch-inference)\n",
    "    1. [Run batch-transform job](#A.-Run-the-batch-transform-job)\n",
    "    1. [Inspect the Output](#B.-Inspect-the-Batch-Transform-Output-in-S3)\n",
    "1. [Clean-up](#6.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page Search Similar Text Descriptions\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn ='arn:aws:sagemaker:us-east-2:786796469737:algorithm/vector-search-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm requires data in the format as described for best results:\n",
    "* Input File name should be input_data.zip\n",
    "* The zip file should contain a CSV file named \"input.csv\" with mandatory information in columns.\n",
    "* The input data files must contain all columns specified in input data description; other columns will be ignored.\n",
    "* For detailed instructions, please refer sample notebook and algorithm input details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='Training Input/input_data.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input uploaded to s3://sagemaker-us-east-2-786796469737/vector-search/training-input-data\n"
     ]
    }
   ],
   "source": [
    "# training input location\n",
    "common_prefix = \"vector-search\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"Training Input\"\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)\n",
    "print(\"Training input uploaded to \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/vector_search/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance `m5.large` is sufficient for training dataset containing ~2000 company descriptions.  \n",
    "Please select an appropriate instance type based on the training dataset size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-02 06:35:39 Starting - Starting the training job...\n",
      "2023-02-02 06:36:03 Starting - Preparing the instances for trainingProfilerReport-1675319739: InProgress\n",
      "......\n",
      "2023-02-02 06:37:03 Downloading - Downloading input data...\n",
      "2023-02-02 06:37:23 Training - Downloading the training image.........\n",
      "2023-02-02 06:39:03 Training - Training image download completed. Training in progress..\u001b[34mStarting the training.\u001b[0m\n",
      "\n",
      "2023-02-02 06:39:38 Uploading - Uploading generated training model\u001b[34m#015Batches:   0%|          | 0/1 [00:00<?, ?it/s]#015Batches: 100%|██████████| 1/1 [00:20<00:00, 20.80s/it]#015Batches: 100%|██████████| 1/1 [00:20<00:00, 20.80s/it]\u001b[0m\n",
      "\u001b[34mLength of the embeddings: 25\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,554 [INFO]: Using 2 omp threads (processes), consider increasing --nb_cores if you have more\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,555 [INFO]: Launching the whole pipeline 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,555 [INFO]: Reading total number of vectors and dimension 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 3292.23it/s]\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,571 [INFO]: There are 25 embeddings of dim 768\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,571 [INFO]: >>> Finished \"Reading total number of vectors and dimension\" in 0.0166 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,572 [INFO]: #011Compute estimated construction time of the index 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,572 [INFO]: #011#011-> Train: 16.7 minutes\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,572 [INFO]: #011#011-> Add: 0.0 seconds\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,573 [INFO]: #011#011Total: 16.7 minutes\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,573 [INFO]: #011>>> Finished \"Compute estimated construction time of the index\" in 0.0012 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,573 [INFO]: #011Checking that your have enough memory available to create the index 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,574 [INFO]: 89.4KB of memory will be needed to build the index (more might be used if you have more)\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,574 [INFO]: #011>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0007 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,574 [INFO]: #011Creating the index 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,574 [INFO]: #011#011-> Instanciate the index HNSW32 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,578 [INFO]: #011#011>>> Finished \"-> Instanciate the index HNSW32\" in 0.0037 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,579 [INFO]: #011#011-> Adding the vectors to the index 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,579 [INFO]: The memory available for adding the vectors is 32.0GB(total available - used by the index)\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,579 [INFO]: Using a batch size of 325520 (memory overhead 953.7MB)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 163.33it/s]\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:30,587 [INFO]: #011Computing best hyperparameters for index /opt/ml/model/experiment_index_allmp/knn.index 02/02/2023, 06:39:30\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,310 [INFO]: #011>>> Finished \"Computing best hyperparameters for index /opt/ml/model/experiment_index_allmp/knn.index\" in 0.7225 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,310 [INFO]: The best hyperparameters are: efSearch=16383\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,310 [INFO]: #011Compute fast metrics 02/02/2023, 06:39:31\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015  0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,381 [INFO]: #011>>> Finished \"Compute fast metrics\" in 0.0705 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,381 [INFO]: #011Saving the index on local disk 02/02/2023, 06:39:31\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,382 [INFO]: #011>>> Finished \"Saving the index on local disk\" in 0.0009 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,382 [INFO]: #011#011>>> Finished \"-> Adding the vectors to the index\" in 0.8036 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,382 [INFO]: {\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011index_key: HNSW32\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011index_param: efSearch=16383\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011index_path: /opt/ml/model/experiment_index_allmp/knn.index\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011size in bytes: 83726\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011avg_search_speed_ms: 0.027638107000029777\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #01199p_search_speed_ms: 0.04453325002231164\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011reconstruction error %: 0.0\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011nb vectors: 25\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011vectors dimension: 768\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011compression ratio: 0.9172777870673386\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: }\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: #011>>> Finished \"Creating the index\" in 0.8087 secs\u001b[0m\n",
      "\u001b[34m2023-02-02 06:39:31,383 [INFO]: >>> Finished \"Launching the whole pipeline\" in 0.8286 secs\u001b[0m\n",
      "\u001b[34mSuccess\u001b[0m\n",
      "\n",
      "2023-02-02 06:40:03 Completed - Training job completed\n",
      "ProfilerReport-1675319739: NoIssuesFound\n",
      "Training seconds: 177\n",
      "Billable seconds: 177\n"
     ]
    }
   ],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"vector-search-training\",\n",
    "    role=role,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type\n",
    ")\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Deploy model and verify results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='vector-search'\n",
    "\n",
    "content_type='application/json'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = estimator.deploy(1, real_time_inference_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model accepts a json file containing the fields `company_name` and `k`.  \n",
    "For detailed instructions, please refer sample input and model input details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '\"Model Input\"/model_input.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = '\"Model Output\"/output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name $predictor.endpoint_name \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type $content_type \\\n",
    "    --region $sagemaker_session.boto_region_name \\\n",
    "    $output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_description</th>\n",
       "      <th>distance_score</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>024 Pharma, Inc.</td>\n",
       "      <td>pharma inc provides healthcare products worldw...</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>Beauty Care Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22nd Century Group, Inc.</td>\n",
       "      <td>nd century group inc plant biotechnology compa...</td>\n",
       "      <td>1.361139</td>\n",
       "      <td>Cigarettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20/20 Global, Inc.</td>\n",
       "      <td>rm investors inc supplies fruits vegetables no...</td>\n",
       "      <td>1.389110</td>\n",
       "      <td>Consumer Staples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PM Industries, Inc.</td>\n",
       "      <td>pm industries inc provides consulting services...</td>\n",
       "      <td>1.411064</td>\n",
       "      <td>Commercial and Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st Prestige Wealth Management</td>\n",
       "      <td>st prestige wealth management provides wealth ...</td>\n",
       "      <td>1.431003</td>\n",
       "      <td>Asset Management and Custody Banks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_name  \\\n",
       "0                024 Pharma, Inc.   \n",
       "1        22nd Century Group, Inc.   \n",
       "2              20/20 Global, Inc.   \n",
       "3            1PM Industries, Inc.   \n",
       "4  1st Prestige Wealth Management   \n",
       "\n",
       "                                 company_description  distance_score  \\\n",
       "0  pharma inc provides healthcare products worldw...        0.642718   \n",
       "1  nd century group inc plant biotechnology compa...        1.361139   \n",
       "2  rm investors inc supplies fruits vegetables no...        1.389110   \n",
       "3  pm industries inc provides consulting services...        1.411064   \n",
       "4  st prestige wealth management provides wealth ...        1.431003   \n",
       "\n",
       "                                industry  \n",
       "0                  Beauty Care Products   \n",
       "1                            Cigarettes   \n",
       "2                      Consumer Staples   \n",
       "3  Commercial and Professional Services   \n",
       "4    Asset Management and Custody Banks   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('Model Output/output.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform Batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Run the batch-transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/vector-search/model_input.json\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"Model Input/model_input.json\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "................................\n",
      "\u001b[34m * Serving Flask app 'serve'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:47] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:47] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:47] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:47] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m#015Batches:   0%|          | 0/1 [00:00<?, ?it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
      "\u001b[34mTop 5 elements in the dataset for max inner product search:\u001b[0m\n",
      "\u001b[34m1: Vector number    2 with distance 0.6427181363105774\u001b[0m\n",
      "\u001b[34m2: Vector number   16 with distance 1.3611392974853516\u001b[0m\n",
      "\u001b[34m3: Vector number   12 with distance 1.3891103267669678\u001b[0m\n",
      "\u001b[34m4: Vector number   20 with distance 1.4110645055770874\u001b[0m\n",
      "\u001b[34m5: Vector number   11 with distance 1.4310033321380615\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:48] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m#015Batches:   0%|          | 0/1 [00:00<?, ?it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
      "\u001b[35mTop 5 elements in the dataset for max inner product search:\u001b[0m\n",
      "\u001b[35m1: Vector number    2 with distance 0.6427181363105774\u001b[0m\n",
      "\u001b[35m2: Vector number   16 with distance 1.3611392974853516\u001b[0m\n",
      "\u001b[35m3: Vector number   12 with distance 1.3891103267669678\u001b[0m\n",
      "\u001b[35m4: Vector number   20 with distance 1.4110645055770874\u001b[0m\n",
      "\u001b[35m5: Vector number   11 with distance 1.4310033321380615\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:48] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[32m2023-02-02T06:50:47.219:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m * Serving Flask app 'serve'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app 'serve'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://169.254.255.131:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:47] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:47] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:47] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:47] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34m#015Batches:   0%|          | 0/1 [00:00<?, ?it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
      "\u001b[34mTop 5 elements in the dataset for max inner product search:\u001b[0m\n",
      "\u001b[34m1: Vector number    2 with distance 0.6427181363105774\u001b[0m\n",
      "\u001b[34m2: Vector number   16 with distance 1.3611392974853516\u001b[0m\n",
      "\u001b[34m3: Vector number   12 with distance 1.3891103267669678\u001b[0m\n",
      "\u001b[34m4: Vector number   20 with distance 1.4110645055770874\u001b[0m\n",
      "\u001b[34m5: Vector number   11 with distance 1.4310033321380615\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2023 06:50:48] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m#015Batches:   0%|          | 0/1 [00:00<?, ?it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]#015Batches: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\u001b[0m\n",
      "\u001b[35mTop 5 elements in the dataset for max inner product search:\u001b[0m\n",
      "\u001b[35m1: Vector number    2 with distance 0.6427181363105774\u001b[0m\n",
      "\u001b[35m2: Vector number   16 with distance 1.3611392974853516\u001b[0m\n",
      "\u001b[35m3: Vector number   12 with distance 1.3891103267669678\u001b[0m\n",
      "\u001b[35m4: Vector number   20 with distance 1.4110645055770874\u001b[0m\n",
      "\u001b[35m5: Vector number   11 with distance 1.4310033321380615\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2023 06:50:48] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[32m2023-02-02T06:50:47.219:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = estimator.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/vector-search-training-2023-02-02-06-45-28-427'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "with open('results.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket, os.path.basename(transformer.output_path)+'/model_input.json.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_description</th>\n",
       "      <th>distance_score</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>024 Pharma, Inc.</td>\n",
       "      <td>pharma inc provides healthcare products worldw...</td>\n",
       "      <td>0.642718</td>\n",
       "      <td>Beauty Care Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22nd Century Group, Inc.</td>\n",
       "      <td>nd century group inc plant biotechnology compa...</td>\n",
       "      <td>1.361139</td>\n",
       "      <td>Cigarettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20/20 Global, Inc.</td>\n",
       "      <td>rm investors inc supplies fruits vegetables no...</td>\n",
       "      <td>1.389110</td>\n",
       "      <td>Consumer Staples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1PM Industries, Inc.</td>\n",
       "      <td>pm industries inc provides consulting services...</td>\n",
       "      <td>1.411064</td>\n",
       "      <td>Commercial and Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st Prestige Wealth Management</td>\n",
       "      <td>st prestige wealth management provides wealth ...</td>\n",
       "      <td>1.431003</td>\n",
       "      <td>Asset Management and Custody Banks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_name  \\\n",
       "0                024 Pharma, Inc.   \n",
       "1        22nd Century Group, Inc.   \n",
       "2              20/20 Global, Inc.   \n",
       "3            1PM Industries, Inc.   \n",
       "4  1st Prestige Wealth Management   \n",
       "\n",
       "                                 company_description  distance_score  \\\n",
       "0  pharma inc provides healthcare products worldw...        0.642718   \n",
       "1  nd century group inc plant biotechnology compa...        1.361139   \n",
       "2  rm investors inc supplies fruits vegetables no...        1.389110   \n",
       "3  pm industries inc provides consulting services...        1.411064   \n",
       "4  st prestige wealth management provides wealth ...        1.431003   \n",
       "\n",
       "                                industry  \n",
       "0                  Beauty Care Products   \n",
       "1                            Cigarettes   \n",
       "2                      Consumer Staples   \n",
       "3  Commercial and Professional Services   \n",
       "4    Asset Management and Custody Banks   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('results.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
